---
title: "Run SDMs"
author: "Simon Rolph"
date: "11/02/2022"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```




### Load packages

```{r}
library(rslurm)
library(dplyr)
library(raster)
library(terra)
library(randomForest)
library(mgcv)

library(dismo)

library(ggplot2)

```

### Parameters

```{r}
n_folds <- 10
species_name <- "pieris_brassicae"
model_to_run <- "glm" 
#model_to_run <- "gam" 
#model_to_run <- "rf" 
#model_to_run <- "maxent" 

```

### Load data

```{r load_data}
#records and pseudoabsences
pas <- readRDS("~/R/DECIDE_SDMs/data/derived_data/species/pas.RDS")

#species list
species_list <- readRDS("~/R/DECIDE_SDMs/data/derived_data/species/species_list.RDS")

#environmental data
env_dat <- raster::stack("data/derived_data/environmental/envdata_fixedcoasts_nocorrs_100m_GB.gri")
#env_dat <- terra::rast(env_dat)


```

### Preparing data

Combine the pres/pseudoabsence with the environmental data to make one data frame that we'll be fitting models to.

```{r}
prepare_data <- function(species_name, pas, env_data){

  #get the presence/absence for the relvant species
  pas_species <- pas[[species_name]]
  
  #for testing purposes subset to 1000 rows
  pas_species$Presence <- pas_species$Presence[1:20000,] %>% as.data.frame()
  pas_species$pseudoAbsence <- pas_species$pseudoAbsence[1:20000,] %>% as.data.frame()

  #extract environmental variables
  env_data <- terra::rast(env_data)
  pres <- data.frame(val = 1,terra::extract(x = env_data, y = pas_species$Presence[,c("lon","lat")]), pas_species$Presence[,c("lon","lat")])
  ab <- data.frame(val = 0, terra::extract(x = env_data, y = pas_species$pseudoAbsence[,c("lon","lat")]), pas_species$pseudoAbsence[,c("lon","lat")])
  
  #remove NAs
  pres <- na.omit(pres)
  ab <- na.omit(ab)
  
  # make into one data frame
  pres_and_ab <- bind_rows(pres,ab)
  pres_and_ab
}

prepared_data <- prepare_data(species_name,pas,env_dat)
head(prepared_data)

```

Define the folds in the data

```{r}

fold_data <- function(prepared_data,n_folds=10){
  prepared_data$fold[prepared_data$val==1] <- prepared_data %>% filter(val == 1) %>% kfold(n_folds)
  prepared_data$fold[prepared_data$val==0] <- prepared_data %>% filter(val == 0) %>% kfold(n_folds)
  prepared_data
}

head(fold_data(prepared_data))

folded_data <- fold_data(prepared_data,n_folds)

```

Determine weightings

if unbalanced number of records vs pseudo-absences the  provide some weighting information. Used for GLM, RF and GAM.

```{r}

determine_weights <- function(folded_data,fold_i){
  n_records <- folded_data %>% filter(val == 1,fold != fold_i) %>% nrow()
  n_abs <- folded_data %>% filter(val == 0,fold != fold_i) %>% nrow()
    
  prop <- n_records / n_abs
  
  #if unbalanced
  if (n_records != n_abs){
    weights <- c(rep(1, n_records), rep(prop, n_abs))
  } else {
    weights <- NULL
  }
  
  weights
}

prepared_data %>% fold_data %>% determine_weights(1)

```

### Fitting models

Models:

 - GLM (`base`?)
 - GAM (`mgcv`)
 - Random forest (`randomForest`)
 - Maxent (`dismo`)

#### Maxent

Maxent models work best with equal number of presences and absences, so should match the number of presences and absences

```{r}
fit_maxent <- function(folded_data,fold_i,env_data){
  options(java.parameters = "-Xmx3g") #https://stackoverflow.com/questions/5374455/what-does-java-option-xmx-stand-for
  
  #fit the model
  mod <- maxent(x = env_data, 
                p = folded_data %>% filter(val == 1, fold != fold_i) %>% dplyr::select(lon,lat), 
                a = (folded_data %>% filter(val == 0, fold != fold_i) %>% dplyr::select(lon,lat))
                )
  
  #evaludate the model
  evaluation <- dismo::evaluate(p = folded_data %>% filter(val == 1, fold == fold_i) %>% dplyr::select(lon,lat), 
                            a = folded_data %>% filter(val == 0, fold == fold_i) %>% dplyr::select(lon,lat), 
                            x = env_data,
                            mod, tr = seq(0, 1, length.out = 200))
  
  #return the model + evaludation
  return(list(model = mod,evaluation = evaluation,summary = summary(mod)))
}

if(model_to_run == "maxent"){
  #test the function
  test_mod1 <- fit_maxent(folded_data,1,env_dat)
  class(test_mod1$model) #determine the class:
  # [1] "MaxEnt"
  # attr(,"package")
  # [1] "dismo"
}

```

#### GLM

Fit a GLM using `glm()`

```{r}
#from https://win-vector.com/2014/05/30/trimming-the-fat-from-glm-models-in-r/
clean_model = function(cm) {
  cm$y = c()
  cm$model = c()
  
  cm$residuals = c()
  cm$fitted.values = c()
  cm$effects = c()
  cm$qr$qr = c()  
  cm$linear.predictors = c()
  cm$weights = c()
  cm$prior.weights = c()
  cm$data = c()
  cm
}

fit_glm <- function(folded_data,fold_i){
  
  weights <- determine_weights(folded_data,fold_i)
  train_data <- folded_data %>% filter(fold != fold_i) %>% dplyr::select(-lat,-lon,-fold,-ID)
  test_data <- folded_data %>% filter(fold == fold_i) %>% dplyr::select(-lat,-lon,-fold,-ID)
  
  mod <- glm(val ~ ., data = train_data, 
                   family = binomial(link = "logit"),
                   weights = weights,
             model = F)
  
  evaluation <- dismo::evaluate(p = test_data %>% filter(val == 1), 
                                  a = test_data %>% filter(val == 0), 
                                  mod, tr = seq(0, 1, length.out = 200))
  mod_summary <- summary(mod)
  
  mod <- clean_model(mod)
  
  #return the model + evaludation
  return(list(model = mod,evaluation = evaluation,summary = mod_summary))
}

if(model_to_run == "glm"){
  #test the function
  test_mod2 <- fit_glm(folded_data,1)
  class(test_mod2$model) #class:
  # [1] "glm" "lm"
}

```


#### Random forest

Fit a random forest with `randomForest` from package `randomForest`

```{r}

fit_rf <- function(folded_data,fold_i){
  weights <- determine_weights(folded_data,fold_i)
  if(!is.null(weights)){
    weights <- list(first(weights),last(weights))
  }
  
  train_data <- folded_data %>% filter(fold != fold_i) %>% dplyr::select(-lat,-lon,-fold,-ID)
  test_data <- folded_data %>% filter(fold == fold_i) %>% dplyr::select(-lat,-lon,-fold,-ID)
  
  mod <- randomForest(x = train_data %>% dplyr::select(-val), 
                      y = train_data %>% dplyr::pull(val) %>% as.factor(), 
                      importance = T, 
                      norm.votes = TRUE)
  
  rf.pred <- predict(mod, type = "prob", newdata = test_data)[,2]
  evaluation <- dismo::evaluate(p = rf.pred[test_data$val == 1], 
                                a = rf.pred[test_data$val == 0], 
                                tr = seq(0, 1, length.out = 200))
  
  #return the model + evaluation
  return(list(model = mod,evaluation = evaluation,summary = summary(mod)))
}

if(model_to_run == "rf"){
  #test the function
  test_mod3 <- fit_rf(folded_data,1)
  class(test_mod3$model)
  # [1] "randomForest"
}
```

#### GAM

Fit a GAM using `gam` from `mgcv`

```{r}

fit_gam <- function(folded_data,fold_i,knots_gam = -1){
  train_data <- folded_data %>% filter(fold != fold_i) %>% dplyr::select(-lat,-lon,-fold,-ID)
  test_data <- folded_data %>% filter(fold == fold_i) %>% dplyr::select(-lat,-lon,-fold,-ID)
  weights <- determine_weights(folded_data,fold_i)
  
  
  ## create formula for gam
  l <- sapply(folded_data %>% filter(fold != fold_i) %>% dplyr::select(-lon,-lat,-fold,-ID), unique)
  ks <- data.frame(variable = rownames(data.frame(k = round(sapply(l, length))[-1])),k = data.frame(k = round(sapply(l, length))[-1]))
  rownames(ks) <- 1:nrow(ks)
  
  # drop variables according to number of knots asked for
  # -1 is basically 9 knots
  if(knots_gam == -1) {
    v_keep <- ks[ks$k > 11,]
    print(paste("variable dropped =", ks$variable[!ks$variable %in% v_keep$variable]))
  }
  
  # any others just keep the variables with over the number of knots
  if(knots_gam > 0) {
    v_keep <- ks[ks$k > (knots_gam+3),]
    print(paste("variable dropped =", ks$variable[!ks$variable %in% v_keep$variable]))
  }
  
  #create the formula
  form <- as.formula(paste0("val ~ s(", paste(v_keep$variable,
                                            ", k = ", knots_gam) %>%
                            paste0(collapse = ") + s("), ")"))
  
  #fit the model
  mod <- gam(formula = form, data = train_data, 
           family = binomial(link = 'logit'), 
           select = TRUE, method = 'REML', gamma = 1.4,
           weights = weights)
  
  
  evaluation <- dismo::evaluate(p = test_data %>% filter(val == 1), 
                                  a = test_data %>% filter(val == 0), 
                                  mod, tr = seq(0, 1, length.out = 200))
  
  #return the model + evaludation
  return(list(model = mod,evaluation = evaluation,summary = summary(mod)))
}

if(model_to_run == "gam"){
  #test the function
  test_mod4 <- fit_gam(folded_data,1)
  class(test_mod4$model)
  # [1] "gam" "glm" "lm"
}


```


```{r}



```

### Make predictions

```{r}
#crop the raster for testing
smaller_extent <- extent(c(370000, 380000, 160000, 170000))
env_dat <- crop(x = env_dat, y = smaller_extent)

```

```{r}
#model list is a list of 10 models fitted from each boostrap
get_predictions <- function(model_list,env_data) {
  print(model_list[[1]]$model)
  
  #get the model class
  model_class <- class(model_list[[1]]$model)
  
  # number of bootstraps that were run
  k = length(model_list)
  
  print(model_class)
  
  # choose the type and index for predict function
  if("glm" %in% model_class){ #"glm" is in the model class for both gams and glms
    type <- "response"
    index <- NULL
  } else if ("randomForest" %in% model_class) {
    type <- "prob"
    index <- 2
  } else if ("MaxEnt" %in% model_class){
    type <- NULL
    index <- NULL
  }
  
  ## bootstrapped models
  print(paste0('#####   predicting from bootstrapped models   #####')) 
  
  # predict from each of the bootstrapped models and stack them together
  boots_out <- raster::stack(lapply(model_list, FUN = function(x) {predict(env_data, x$model, type=type, index=index)} ))
  
  ## quantiles
  print(paste0('#####   getting standard deviation   #####'))
  mean_preds <- calc(boots_out, fun = mean, na.rm = T) # the mean
  rnge <- calc(boots_out, fun = function(x) {sd(x, na.rm = TRUE)}) # get the standard deviation
  # rnge <- quant_preds[[2]]-quant_preds[[1]] # get the range of max - min
    

  return(list(mean_predictions = mean_preds,
              quant_range = rnge))
}

#test
if(F){
  test <- get_predictions(list(test_mod1,test_mod1,test_mod1,test_mod1),env_dat)
}

```

Fit the models and run predictions

```{r}

folds_list <- as.list(1:n_folds)

#run the models on the folded data
if(model_to_run == "glm"){
  
  mods <- lapply(folds_list,FUN = function(x){
    fit_glm(folded_data,x)
    })
  
} else if(model_to_run == "gam"){
  
  mods <- lapply(folds_list,FUN = function(x){
    fit_gam(folded_data,x)
    })
  
} else if(model_to_run == "rf"){
  
  mods <- lapply(folds_list,FUN = function(x){
    fit_rf(folded_data,x)
    })
  
} else if(model_to_run == "maxent"){
  
  mods <- lapply(folds_list,FUN = function(x){
    fit_maxent(folded_data,x)
    })
  
}

#get predictions
predictions <- get_predictions(mods,env_dat)

# object.size(mods) %>% format(units = "Mb")
# object.size(predictions) %>% format(units = "Mb")

```

Saving objects 

 * rasters for mean and bootstrapped model uncertainty
 * one of the boostrapped models (ideally without all the data)
 * summaries from all of the models

```{r}

#save rasters

#write prediction
#raster::writeRaster()

#write SDM uncertainty
#raster::writeRaster()


#calculate mean AUC across all models, and generate summaries
AUCs <- sapply(mods, function(x) {slot(x$evaluation, "auc")})
mean_AUC <- AUCs %>% mean()
summaries <- lapply(mods,FUN = function(x){x$summary})

#remove the models for all but the first bootstrap
#but retain evaluations and summaries
for (i in 2:n_folds){
  mods[[i]]$model <- NULL
}

#check model size
object.size(mods) %>% format(units = "Mb")

#create one object for saving
output <- 
  list(mods,
       AUCs = AUCs,
       mean_AUC = mean_AUC,
       summaries = summaries)

#check size of this object
object.size(output) %>% format(units = "Mb") # all models

#save output
saveRDS(output,file = paste0("data/derived_data/model_outputs_by_species/",model_to_run,"/",species_name,".rds"))

```


### Diagnostic plots

```{r}

plot_diags <- F

if(plot_diags){
  #generic diagnostic plot
  plot(mods[[1]]$model)
  
  #mean prediction versus sd
  plot(x = values(predictions$mean_predictions),y = values(predictions$quant_range))
  
  #cap big values
  values(predictions$quant_range)[values(predictions$quant_range)>0.0025] <- 0.0025
  
  #compare predicted vs actual (and pseudo)
  test <- data.frame(folded_data[,c("lon","lat","val")],prediction =terra::extract(x = predictions$mean_predictions, y = folded_data[,c("lon","lat")])) %>% na.omit(test)
  test %>%
    ggplot(aes(x = val, y = prediction))+
    geom_point()
  
  #turn raster into a data frame for ggplotting
  test_spdf <- as(predictions$mean_predictions, "SpatialPixelsDataFrame")
  test_df <- as.data.frame(test_spdf)
  colnames(test_df) <- c("value", "x", "y")
  
  #plot raster and points
  test %>%
    filter(val == 1) %>%
    ggplot(aes(x = lon,y = lat))+
    geom_tile(data=test_df, aes(x=x, y=y, fill=value), alpha=1)+
    scale_fill_gradient(low = "aliceblue",high = "chartreuse3")+
    geom_point(alpha = 1,shape = 16)+
    theme_classic()+
    labs(fill = "Probability of presence",x = "Eastings",y = "Northings")+
    coord_fixed()
    
  
  #turn raster into a data frame for ggplotting
  test_spdf <- as(predictions$quant_range, "SpatialPixelsDataFrame")
  test_df <- as.data.frame(test_spdf)
  colnames(test_df) <- c("value", "x", "y")
  
  #plot raster and points
  test %>% 
    filter(val == 1) %>%
    ggplot(aes(x = lon,y = lat))+
    geom_tile(data=test_df, aes(x=x, y=y, fill=(log(value)+8.1)/5), alpha=1)+
    scale_fill_gradient(low = "aliceblue",high = "coral1")+
    geom_point(alpha = 1,shape = 16)+
    theme_classic()+
    labs(fill = "Model Uncertainty",x = "Eastings",y = "Northings")+
    coord_fixed()
}



```






```{r}


print("done")

```






